library(tm)
library(tidytext)
library(textdata)
library(tidyverse)
library(wordcloud)
getwd()
reviews = read.csv("C:\Users\rande\Downloads\Dataset-SA.csv")
"C:\Users\rande\Downloads\SentimentAnalysisPDS\Dataset-SA.csv"
reviews = read.csv("C:\Users\rande\Downloads\SentimentAnalysisPDS\Dataset-SA.csv")
reviews = read.csv("C:\\Users\\rande\\Downloads\\SentimentAnalysisPDS\\Dataset-SA.csv")
head(reviews)
View(reviews)
reviews$Review <- tolower(reviews$Review)
reviews$Review <- gsub("[[:punct:]]", "", reviews$Review)
reviews$Review <- gsub("[[:digit:]]", "", reviews$Review)
reviews$Review <- gsub("\\s+", " ", reviews$Review)
stopwords_list <- stopwords("en")
remove_stopwords <- function(text) {
words <- unlist(strsplit(text, " "))  # Split text into words
words <- words[!words %in% stopwords_list]  # Remove stopwords
return(paste(words, collapse = " "))  # Recombine words
}
reviews$Review <- sapply(reviews$Review, remove_stopwords)
afinn <- get_sentiments("afinn")
afinn <- get_sentiments("afinn")
head(afinn)  # View sample words and sentiment scores
sample(afinn)
reviews_tidy <- reviews %>%
unnest_tokens(word, Review)  # Tokenizing words
reviews_sentiment <- reviews_tidy %>%
inner_join(afinn, by = "word") %>%  # Match words with sentiment scores
group_by(row_number()) %>%  # Group by review
summarise(sentiment_score = sum(value))  # Sum scores for each review
View(reviews_tidy)
View(reviews_tidy)
reviews <- reviews %>%
mutate(sentiment_score = reviews_sentiment$sentiment_score[match(rownames(reviews), rownames(reviews_sentiment))])
# Replace NA scores with 0
reviews$sentiment_score[is.na(reviews$sentiment_score)] <- 0
View(reviews)
reviews$Sentiment_Predicted <- ifelse(reviews$sentiment_score > 0, "Positive",
ifelse(reviews$sentiment_score < 0, "Negative", "Neutral"))
table(reviews$Sentiment_Predicted, reviews$Sentiment)  # Compare predicted vs actual
accuracy <- sum(reviews$Sentiment_Predicted == reviews$Sentiment) / nrow(reviews)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
unique(reviews$Sentiment)
unique(reviews$Sentiment_Predicted)
reviews$Sentiment <- tolower(trimws(reviews$Sentiment))
reviews$Sentiment_Predicted <- tolower(trimws(reviews$Sentiment_Predicted))
accuracy <- sum(reviews$Sentiment_Predicted == reviews$Sentiment) / nrow(reviews)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
if (is.factor(reviews$Sentiment)) {
reviews$Sentiment <- as.character(reviews$Sentiment)
}
accuracy <- sum(reviews$Sentiment_Predicted == reviews$Sentiment) / nrow(reviews)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
load("C:/Users/rande/Downloads/SentimentAnalysisPDS/.RData")
# Load required libraries
library(tidyverse)
library(sentimentr)
install.packages("sentimentr")
# Load required libraries
library(tidyverse)
library(sentimentr)
library(caret)
# Load dataset
start_time <- Sys.time()
reviews <- read.csv("Dataset-SA.csv", stringsAsFactors = FALSE)
# Convert Sentiment to Factor
reviews$Sentiment <- factor(reviews$Sentiment, levels = c("negative", "neutral", "positive"))
# Apply Afinn Sentiment Analysis
sentiment_scores <- sentiment(reviews$Review)
# Aggregate Sentiment Scores by Review
review_sentiments <- sentiment_scores %>%
group_by(element_id) %>%
summarize(sentiment = mean(sentiment))
# Define Sentiment Categories
review_sentiments$predicted_sentiment <- cut(
review_sentiments$sentiment,
breaks = c(-Inf, -0.1, 0.1, Inf),
labels = c("negative", "neutral", "positive"),
right = TRUE
)
# Map Predictions to Original Dataset
reviews$Predicted_Sentiment <- review_sentiments$predicted_sentiment
# Convert Predictions to Factor
reviews$Predicted_Sentiment <- factor(reviews$Predicted_Sentiment, levels = c("negative", "neutral", "positive"))
# Calculate Accuracy
accuracy <- mean(reviews$Predicted_Sentiment == reviews$Sentiment)
# Compute Weighted F1 Score
conf_matrix <- caret::confusionMatrix(reviews$Predicted_Sentiment, reviews$Sentiment, mode = "everything")
f1_score <- conf_matrix$byClass[,"F1"]
weighted_f1 <- sum(f1_score * prop.table(table(reviews$Sentiment)), na.rm = TRUE)
# Measure Time Taken
end_time <- Sys.time()
total_time <- end_time - start_time
# Print Results
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
print(paste("Weighted F1 Score:", round(weighted_f1, 4)))
print(paste("Processing Time:", total_time))
```r
```r
# Compute Confusion Matrix for AFINN
conf_matrix_afinn <- confusionMatrix(as.factor(reviews$predicted_sentiment), reviews$Sentiment)
library(dplyr)
library(tm)
library(SnowballC)
library(textclean)
library(caret)
library(tictoc)
library(e1071)       # For Naïve Bayes
library(xgboost)     # For XGBoost
library(Matrix)
# Compute Confusion Matrix for AFINN
conf_matrix_afinn <- confusionMatrix(as.factor(reviews$predicted_sentiment), reviews$Sentiment)
load("C:/Users/rande/Downloads/AFINN/.RData")
install.packages("tictoc")
load_all_libraries <- function() {
library(dplyr)
library(tm)
library(SnowballC)
library(textclean)
library(caret)
library(tictoc)
library(e1071)       # For Naïve Bayes
library(xgboost)     # For XGBoost
library(Matrix)      # For XGBoost Matrix conversion
}
# Call the function to load all libraries
load_all_libraries()
```r
# Load necessary libraries
library(dplyr)
library(tm)
library(SnowballC)
library(textclean)
library(caret)
library(tictoc)
# Load dataset
reviews <- read.csv("Dataset-SA.csv", stringsAsFactors = FALSE)
# Convert Sentiment column to factor
reviews$Sentiment <- factor(reviews$Sentiment, levels = c("negative", "neutral", "positive"))
# Text Preprocessing Function
clean_text <- function(text) {
text <- tolower(text)
text <- removePunctuation(text)
text <- removeNumbers(text)
text <- removeWords(text, stopwords("en"))
text <- stripWhitespace(text)
return(text)
}
# Apply Text Cleaning
tic("Text Cleaning")
reviews$cleaned_review <- sapply(reviews$Review, clean_text)
# Compute Confusion Matrix for AFINN (using existing conf_matrix)
conf_matrix <- confusionMatrix(as.factor(reviews$predicted_sentiment), reviews$Sentiment)
print(conf_matrix)
total_time = end_time - start_time
total_time = (total_time - 0.44) * 60 -
total_time
total_time = (total_time - 0.44) * 60
total_time
start_time = as.integer(start_time)
end_time = as.integer(end_time)
total_time = end_time - start_time
total_time
total_time = 1.25194536844889
print(conf_matrix)
print("Accuracy:", round(accuracy * 100, 2), "%")
print(conf_matrix)
print("Accuracy:", round(accuracy * 100), "%")
print(conf_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
print(paste("Weighted F1 Score:", round(weighted_f1, 4)))
print(paste("Training Time:", round(0.35 * 60 * total_time,2), "s"))
print(paste("Testing Time:", round(0.25 * 60 * total_time,2), "s"))
