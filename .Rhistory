# Install necessary packages (if not installed)
install.packages("xgboost")
install.packages("caret")
install.packages("Matrix")
install.packages("e1071")  # Needed for confusionMatrix
install.packages("microbenchmark")  # For measuring training/testing time
# Load libraries
library(xgboost)
library(caret)
library(Matrix)
library(e1071)
library(microbenchmark)
# Load dataset
reviews <- read.csv("C:\\Users\\rande\\Downloads\\XGBoost\\Dataset-SA.csv", stringsAsFactors = FALSE)
# Convert Sentiment to Factor
reviews$Sentiment <- factor(reviews$Sentiment, levels = c("negative", "neutral", "positive"))
# Convert Review Column to Character (if not already)
reviews$Review <- as.character(reviews$Review)
# Load text processing libraries
install.packages("quanteda")
library(quanteda)
# Create a text corpus
corpus <- corpus(reviews$Review)
# Tokenization & Document-Term Matrix
dtm <- dfm(tokens(corpus))
# Trim sparse terms (remove rare words)
dtm <- dfm_trim(dtm, min_termfreq = 10)
# Select only top 500 words
top_words <- names(topfeatures(dtm, 500))
dtm <- dfm_select(dtm, pattern = top_words)
# Convert DTM to matrix
dtm_matrix <- convert(dtm, to = "matrix")
# Convert to DataFrame
reviews_clean <- as.data.frame(dtm_matrix)
reviews_clean$Sentiment <- reviews$Sentiment  # Add target column
# Ensure unique column names (Fix Duplicates)
colnames(reviews_clean) <- make.names(colnames(reviews_clean), unique = TRUE)
set.seed(42)  # For reproducibility
train_index <- sample(1:nrow(reviews_clean), 0.8 * nrow(reviews_clean))
train_df <- reviews_clean[train_index, ]
test_df  <- reviews_clean[-train_index, ]
# Convert target variable to numeric for XGBoost (Required)
train_labels <- as.numeric(train_df$Sentiment) - 1  # Convert factors to 0,1,2
test_labels  <- as.numeric(test_df$Sentiment) - 1
# Remove Sentiment column from train and test datasets
train_df$Sentiment <- NULL
test_df$Sentiment <- NULL
# Convert DataFrame to XGBoost DMatrix format
train_matrix <- xgb.DMatrix(data = as.matrix(train_df), label = train_labels)
test_matrix  <- xgb.DMatrix(data = as.matrix(test_df), label = test_labels)
# Define parameters for XGBoost
params <- list(
objective = "multi:softmax",  # Multi-class classification
num_class = 3,  # Number of sentiment classes (negative, neutral, positive)
eval_metric = "mlogloss",  # Log loss for evaluation
eta = 0.1,  # Learning rate
max_depth = 6,  # Tree depth
nthread = 4  # Parallel processing
)
# Measure Training Time
train_time <- microbenchmark(
xgb_model <- xgboost(
params = params,
data = train_matrix,
nrounds = 100,  # Number of boosting rounds
verbose = 1
),
times = 1
)
# Print training time
print(train_time)
# Measure Testing Time
test_time <- microbenchmark(
predictions <- predict(xgb_model, newdata = test_matrix),
times = 1
)
# Print Testing Time
print(test_time)
# Convert Predictions to Factors
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Compute Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_df$Sentiment)
# Convert Predictions to Factor with Correct Levels
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
test_labels <- factor(test_labels, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Compute Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_labels)
print(levels(predictions))
print(levels(test_labels))
# Convert Predictions to Factors
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Compute Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_df$Sentiment)
print(class(predictions))  # Should return "factor"
print(class(test_labels))  # Should return "factor"
predictions <- as.factor(predictions)
test_labels <- as.factor(test_labels)
print(levels(predictions))
print(levels(test_labels))
levels(predictions) <- c("negative", "neutral", "positive")
levels(test_labels) <- c("negative", "neutral", "positive")
sum(is.na(predictions))  # Should be 0
sum(is.na(test_labels))  # Should be 0
table(is.na(predictions))
sum(is.na(test_labels))
valid_idx <- !is.na(predictions)  # Get indices of valid predictions
predictions <- predictions[valid_idx]  # Keep only valid predictions
test_labels <- test_labels[valid_idx]  # Ensure corresponding labels match
conf_matrix <- confusionMatrix(predictions, test_labels)
print(conf_matrix)
nrow(test_df)  # Or however you're splitting your data
length(predictions)  # Ensure they match
length(test_labels)  # Ensure they match
table(predictions, useNA = "always")
table(test_labels, useNA = "always")
sample_review <- test_df[1, , drop = FALSE]  # Get a single row
sample_prediction <- predict(xgb_model, as.matrix(sample_review))
print(sample_prediction)
setdiff(colnames(train_df), colnames(test_df))  # Should return character(0)
print(levels(predictions))
print(levels(test_labels))
nrow(test_df)  # Or however you're splitting your data
length(predictions)  # Ensure they match
length(test_labels)  # Ensure they match
# Convert Predictions to Factors
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Compute Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_df$Sentiment)
probabilities <- predict(xgb_model, as.matrix(test_df), type = "prob")
print(head(probabilities))  # See if you get any values
predictions <- apply(probabilities, 1, function(x) colnames(probabilities)[which.max(x)])
print(all.equal(colnames(train_df), colnames(test_df)))  # Should return TRUE
test_labels <- factor(test_labels, levels = c("negative", "neutral", "positive"))
set.seed(42)  # For reproducibility
train_index <- sample(1:nrow(reviews_clean), 0.8 * nrow(reviews_clean))
train_df <- reviews_clean[train_index, ]
test_df  <- reviews_clean[-train_index, ]
# Convert target variable to numeric for XGBoost (Required)
train_labels <- as.numeric(train_df$Sentiment) - 1  # Convert factors to 0,1,2
test_labels  <- as.numeric(test_df$Sentiment) - 1
# Remove Sentiment column from train and test datasets
train_df$Sentiment <- NULL
test_df$Sentiment <- NULL
# Convert DataFrame to XGBoost DMatrix format
train_matrix <- xgb.DMatrix(data = as.matrix(train_df), label = train_labels)
test_matrix  <- xgb.DMatrix(data = as.matrix(test_df), label = test_labels)
# Define parameters for XGBoost
params <- list(
objective = "multi:softmax",  # Multi-class classification
num_class = 3,  # Number of sentiment classes (negative, neutral, positive)
eval_metric = "mlogloss",  # Log loss for evaluation
eta = 0.1,  # Learning rate
max_depth = 6,  # Tree depth
nthread = 4  # Parallel processing
)
# Measure Training Time
train_time <- microbenchmark(
xgb_model <- xgboost(
params = params,
data = train_matrix,
nrounds = 100,  # Number of boosting rounds
verbose = 1
),
times = 1
)
# Print training time
print(train_time)
sum(is.na(test_df))  # Should be 0
sum(is.infinite(as.matrix(test_df)))  # Should be 0
# Measure Testing Time
test_time <- microbenchmark(
predictions <- predict(xgb_model, newdata = test_matrix),
times = 1
)
# Print Testing Time
print(test_time)
# Convert Predictions to Factors
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Compute Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_df$Sentiment)
test_df[is.na(test_df)] <- 0
test_df[is.infinite(as.matrix(test_df))] <- 0
# Convert Predictions to Factors
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Compute Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_df$Sentiment)
print(levels(factor(predictions)))
print(levels(factor(test_labels)))
test_labels <- factor(test_labels, levels = c("negative", "neutral", "positive"))
predictions <- factor(predictions, levels = c("negative", "neutral", "positive"))
conf_matrix <- confusionMatrix(predictions, test_labels)
print(conf_matrix)
table(predictions)
dim(train_df)  # Should show (large number, many columns)
dim(test_df)   # Should show (large number, many columns)
colSums(train_df[, -ncol(train_df)])  # Exclude the Sentiment column
colSums(test_df[, -ncol(test_df)])
table(train_df$Sentiment)
table(test_df$Sentiment)
set.seed(42)
small_train <- train_df[sample(nrow(train_df), 5000), ]  # Use only 5000 rows
small_test <- test_df[sample(nrow(test_df), 2000), ]
# Train the model on smaller dataset
model <- xgboost(data = as.matrix(small_train[, -ncol(small_train)]),
label = as.numeric(small_train$Sentiment) - 1,
nrounds = 10,  # Reduce rounds for quick test
objective = "multi:softmax",
num_class = 3)
# Install missing packages (ONLY RUN ONCE)
packages <- c("quanteda", "xgboost", "caret", "microbenchmark", "Matrix")
new_packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load Libraries
library(quanteda)
library(xgboost)
library(caret)
library(microbenchmark)
library(Matrix)
# Load Dataset
reviews <- read.csv("C:\\Users\\rande\\Downloads\\XGBoost\\Dataset-SA.csv", stringsAsFactors = FALSE)
# Convert Sentiment to Factor (XGBoost needs numeric labels)
reviews$Sentiment <- factor(reviews$Sentiment, levels = c("negative", "neutral", "positive"))
# Convert Review Column to Character (Fixes corpus() error)
reviews$Review <- as.character(reviews$Review)
# Check for missing values
reviews <- na.omit(reviews)  # Remove missing rows if any
# Create Text Corpus
corpus <- corpus(reviews$Review)
# Tokenize & Create Document-Term Matrix
dtm <- dfm(tokens(corpus))
# Trim Sparse Terms & Keep Most Frequent Words
dtm <- dfm_trim(dtm, min_termfreq = 10)
top_words <- names(topfeatures(dtm, 500))  # Keep top 500 words
dtm <- dfm_select(dtm, pattern = top_words)
# Convert DTM to Matrix
dtm_matrix <- convert(dtm, to = "matrix")
# Convert to Data Frame & Add Target Column
reviews_clean <- as.data.frame(dtm_matrix)
reviews_clean$Sentiment <- reviews$Sentiment  # Add Sentiment Column
# Fix Duplicated Column Names
colnames(reviews_clean) <- make.names(colnames(reviews_clean), unique = TRUE)
# Convert Sentiment Labels to Numeric (XGBoost Requirement)
reviews_clean$Sentiment <- as.numeric(reviews_clean$Sentiment) - 1
set.seed(42)  # Ensure reproducibility
train_index <- sample(1:nrow(reviews_clean), 0.8 * nrow(reviews_clean))
train_df <- reviews_clean[train_index, ]
test_df  <- reviews_clean[-train_index, ]
# Convert to XGBoost DMatrix (Optimized Data Format)
train_matrix <- xgb.DMatrix(data = as.matrix(train_df[, -ncol(train_df)]), label = train_df$Sentiment)
test_matrix  <- xgb.DMatrix(data = as.matrix(test_df[, -ncol(test_df)]), label = test_df$Sentiment)
# Define Parameters
params <- list(
objective = "multi:softmax",  # Multiclass Classification
num_class = 3,                # 3 Sentiment Classes
eval_metric = "mlogloss",      # Log Loss for Multiclass
max_depth = 6,                 # Depth of Trees
eta = 0.3,                     # Learning Rate
nthread = parallel::detectCores() - 1  # Use all cores except one
)
# Measure Training Time
start_time <- Sys.time()
# Train the Model
xgb_model <- xgboost(
params = params,
data = train_matrix,
nrounds = 100,  # Number of boosting rounds
verbose = TRUE
)
end_time <- Sys.time()
train_time <- end_time - start_time
print(paste("Training Time:", round(train_time, 2), "seconds"))
start_time <- Sys.time()
predictions <- predict(xgb_model, test_matrix)
end_time <- Sys.time()
test_time <- end_time - start_time
print(paste("Testing Time:", round(test_time, 2), "seconds"))
# Convert Predictions to Factor (Match Original Labels)
predictions <- factor(predictions, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Convert Actual Labels to Factor for Comparison
test_labels <- factor(test_df$Sentiment, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_labels)
print(conf_matrix)
# Weighted F1 Score
f1_score <- conf_matrix$byClass[, "F1"]
weighted_f1 <- sum(f1_score * prop.table(table(test_labels)), na.rm = TRUE)
print(paste("Weighted F1 Score:", round(weighted_f1, 4)))
# Accuracy
accuracy <- sum(predictions == test_labels) / length(test_labels)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
print(conf_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
print(paste("Weighted F1 Score:", round(weighted_f1, 4)))
print(paste("Training Time:", round(training_time, 2), "seconds"))
# Load required library
library(caret)
# Generate Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_labels)
# Extract Weighted F1 Score
f1_score <- conf_matrix$byClass[, "F1"]
weighted_f1 <- sum(f1_score * table(test_labels) / length(test_labels), na.rm = TRUE)
# Print Weighted F1 Score
print(paste("Weighted F1 Score:", round(weighted_f1, 4)))
# Measure Training Time
start_train <- Sys.time()
xgb_model <- xgboost(
data = train_matrix, label = train_labels,
nrounds = 50, objective = "multi:softmax",
num_class = 3, eval_metric = "mlogloss"
)
library(xgboost)
# Measure Training Time
start_train <- Sys.time()
xgb_model <- xgboost(
data = train_matrix, label = train_labels,
nrounds = 50, objective = "multi:softmax",
num_class = 3, eval_metric = "mlogloss"
)
start_time <- Sys.time()
predictions <- predict(xgb_model, test_matrix)
load_libraries <- function() {
library(dplyr)
library(tm)
library(SnowballC)
library(textclean)
library(caret)
library(tictoc)
library(e1071)       # For NaÃ¯ve Bayes
library(nnet)        # For Logistic Regression
library(xgboost)     # For XGBoost
library(Matrix)      # For sparse matrix conversion in XGBoost
}
load_libraries()
# Load Dataset
reviews <- read.csv("Dataset-SA.csv", stringsAsFactors = FALSE)
# Convert Sentiment to Factor (XGBoost needs numeric labels)
reviews$Sentiment <- factor(reviews$Sentiment, levels = c("negative", "neutral", "positive"))
# Convert Review Column to Character (Fixes corpus() error)
reviews$Review <- as.character(reviews$Review)
# Check for missing values
reviews <- na.omit(reviews)  # Remove missing rows if any
# Create Text Corpus
corpus <- corpus(reviews$Review)
# Tokenize & Create Document-Term Matrix
dtm <- dfm(tokens(corpus))
# Trim Sparse Terms & Keep Most Frequent Words
dtm <- dfm_trim(dtm, min_termfreq = 10)
top_words <- names(topfeatures(dtm, 500))  # Keep top 500 words
dtm <- dfm_select(dtm, pattern = top_words)
# Convert DTM to Matrix
dtm_matrix <- convert(dtm, to = "matrix")
# Convert to Data Frame & Add Target Column
reviews_clean <- as.data.frame(dtm_matrix)
reviews_clean$Sentiment <- reviews$Sentiment  # Add Sentiment Column
# Fix Duplicated Column Names
colnames(reviews_clean) <- make.names(colnames(reviews_clean), unique = TRUE)
# Convert Sentiment Labels to Numeric (XGBoost Requirement)
reviews_clean$Sentiment <- as.numeric(reviews_clean$Sentiment) - 1
set.seed(42)  # Ensure reproducibility
train_index <- sample(1:nrow(reviews_clean), 0.8 * nrow(reviews_clean))
train_df <- reviews_clean[train_index, ]
test_df  <- reviews_clean[-train_index, ]
# Convert to XGBoost DMatrix (Optimized Data Format)
train_matrix <- xgb.DMatrix(data = as.matrix(train_df[, -ncol(train_df)]), label = train_df$Sentiment)
test_matrix  <- xgb.DMatrix(data = as.matrix(test_df[, -ncol(test_df)]), label = test_df$Sentiment)
# Define Parameters
params <- list(
objective = "multi:softmax",  # Multiclass Classification
num_class = 3,                # 3 Sentiment Classes
eval_metric = "mlogloss",      # Log Loss for Multiclass
max_depth = 6,                 # Depth of Trees
eta = 0.3,                     # Learning Rate
nthread = parallel::detectCores() - 1  # Use all cores except one
)
# Measure Training Time
start_time <- Sys.time()
# Train the Model
xgb_model <- xgboost(
params = params,
data = train_matrix,
nrounds = 100,  # Number of boosting rounds
verbose = TRUE
)
end_time <- Sys.time()
train_time <- end_time - start_time
print(paste("Training Time:", round(train_time, 2), "seconds"))
# Convert Actual Labels to Factor for Comparison
test_labels <- factor(test_df$Sentiment, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_labels)
print(conf_matrix)
# Weighted F1 Score
f1_score <- conf_matrix$byClass[, "F1"]
weighted_f1 <- sum(f1_score * prop.table(table(test_labels)), na.rm = TRUE)
print(paste("Weighted F1 Score:", round(weighted_f1, 4)))
# Accuracy
accuracy <- sum(predictions == test_labels) / length(test_labels)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# Measure Training Time
start_train <- Sys.time()
xgb_model <- xgboost(
data = train_matrix, label = train_labels,
nrounds = 50, objective = "multi:softmax",
num_class = 3, eval_metric = "mlogloss"
)
# Measure Training Time
start_train <- Sys.time()
xgb_model <- xgboost(
data = train_matrix, label = test_labels,
nrounds = 50, objective = "multi:softmax",
num_class = 3, eval_metric = "mlogloss"
)
# Measure Testing Time
test_start_time <- Sys.time()
# Make Predictions
predictions <- predict(xgb_model, test_matrix)
test_end_time <- Sys.time()
# Calculate Test Time
test_time <- test_end_time - test_start_time
print(paste("Testing Time:", round(as.numeric(test_time), 4), "seconds"))
# Convert Actual Labels to Factor for Comparison
test_labels <- factor(test_df$Sentiment, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_labels)
# Convert Actual Labels to Factor for Comparison
test_labels <- factor(test_df$Sentiment, levels = c(0, 1, 2), labels = c("negative", "neutral", "positive"))
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_labels)
